{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9927ad3c",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "48a9b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import unidecode\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f8676d",
   "metadata": {},
   "source": [
    "Function that checks the validity of our player keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "f4f6611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_links(ids):\n",
    "    base_url = \"https://www.basketball-reference.com/players\"\n",
    "    ids_to_remove = []\n",
    "    \n",
    "    for id_ in ids:\n",
    "        link = f\"{base_url}/{str(id_)[0]}/{str(id_)}.html\"\n",
    "        response = requests.head(link)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Not working: {link}\")\n",
    "            ids_to_remove.append(id_)\n",
    "        else:\n",
    "            print(\"Working\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "    return ids_to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38426557",
   "metadata": {},
   "source": [
    "Function that removes accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "7e4fc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    \n",
    "    return nfkd_form.encode('ASCII', 'ignore').decode('ASCII')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44671bbe",
   "metadata": {},
   "source": [
    "Function that extracts all the active player names for a given season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "9e135f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_players(year):\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_totals.html\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'totals_stats'})\n",
    "    players = [td.a.getText() for td in table.findAll('td', {'data-stat': 'player'})]\n",
    "    \n",
    "    return list(set(players))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e205c2",
   "metadata": {},
   "source": [
    "## Injured players IDs extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "id": "ee722272",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('injuries.txt'):\n",
    "    injuries_data = []\n",
    "    with open('url_str.txt', 'r') as file: url_base = file.read()\n",
    "    \n",
    "    for i in range(0, 442):\n",
    "        url_str = url_base + str(25 * i)\n",
    "        req = requests.get(url_str)\n",
    "        soup = BeautifulSoup(req.content, 'lxml')\n",
    "\n",
    "        for item in soup.find_all(\"tr\", {\"align\":\"left\"}):\n",
    "            raw_text = item.text.strip().split(\"\\n\")\n",
    "            injuries_data.append(raw_text)\n",
    "        print(\"Working\")\n",
    "else:\n",
    "    injuries_df = pd.read_csv('injuries.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "id": "70f486fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('injuries.txt'):\n",
    "    injuries_df = pd.DataFrame(injuries_data)\n",
    "    injuries_df.columns = [\"Date\", \"Team\", \"Player Out\", \"Player In\", \"Reason\"]\n",
    "\n",
    "    injuries_df = injuries_df.drop(columns=[\"Player Out\", \"Reason\"])\n",
    "    injuries_df = injuries_df[injuries_df[\"Player In\"].str.strip() != '']\n",
    "    injuries_df = injuries_df[injuries_df[\"Team\"].str.strip() != '']\n",
    "\n",
    "    injuries_df.reset_index(drop=True, inplace=True)\n",
    "    injuries_df[\"Player In\"] = injuries_df[\"Player In\"].str.lstrip(\"â€¢ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "ea1d5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('injuries.txt'):\n",
    "    injuries_df[\"Player In\"] = injuries_df[\"Player In\"].str.replace(r'\\([^)]*\\)', '')\n",
    "    injuries_df[\"Player In\"] = injuries_df[\"Player In\"].str.replace('.', '')\n",
    "    injuries_df[\"Player In\"] = injuries_df[\"Player In\"].str.replace('\\'', '')\n",
    "    injuries_df[\"Player In\"] = injuries_df[\"Player In\"].str.replace('-', '')\n",
    "    injuries_df[\"Player In\"] = injuries_df[\"Player In\"].str.split(\" /\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "id": "5801cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('injuries.txt'):\n",
    "    name_split_df = injuries_df[\"Player In\"].str.split(n=1, expand=True)\n",
    "    injuries_df[\"First Name\"] = name_split_df[0]\n",
    "    injuries_df[\"Last Name\"] = name_split_df[1]\n",
    "    injuries_df[\"First Name\"] = injuries_df[\"First Name\"].str.replace(' ', '')\n",
    "    injuries_df[\"Last Name\"] = injuries_df[\"Last Name\"].str.replace(' ', '')\n",
    "\n",
    "    injuries_df[\"Final ID\"] = (injuries_df[\"Last Name\"].str[:5] + injuries_df[\"First Name\"].str[:2] + '01').str.lower()\n",
    "    injuries_df = injuries_df.drop(columns=[\"Player In\", \"First Name\", \"Last Name\", \"Team\"])\n",
    "    injuries_df = injuries_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c30ac6",
   "metadata": {},
   "source": [
    "Saving the dataframe as txt to avoid having to reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "b5929401",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('injuries.txt'):\n",
    "    injuries_df.to_csv('injuries.txt', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04c292",
   "metadata": {},
   "source": [
    "## Total players IDs extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "e57c4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('players.txt'):\n",
    "    start_year = 2013\n",
    "    end_year = 2023\n",
    "\n",
    "    all_unique_players = []\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        unique_players = extract_unique_players(year)\n",
    "        all_unique_players.extend(unique_players)\n",
    "\n",
    "    all_unique_players = list(set(all_unique_players))\n",
    "else:\n",
    "    players_df = pd.read_csv('players.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "b53e63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('players.txt'):\n",
    "    all_unique_players = [element.replace('.', '') for element in all_unique_players]\n",
    "    all_unique_players = [element.replace('-', '') for element in all_unique_players]\n",
    "    all_unique_players = [element.replace('\\'', '') for element in all_unique_players]\n",
    "    all_unique_players = [name.replace(' Jr', '') for name in all_unique_players]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "9f6bf511",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('players.txt'):\n",
    "    final_column = []\n",
    "\n",
    "    for name in all_unique_players:\n",
    "        parts = name.split(' ')\n",
    "        last_name = parts[-1][:5]\n",
    "        first_name = parts[0][:2]\n",
    "        final_id = (last_name + first_name + '01').lower()\n",
    "        final_column.append(final_id)\n",
    "\n",
    "    players_id_df = pd.DataFrame(final_column, columns=['Final ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c9b69",
   "metadata": {},
   "source": [
    "We chose to remove the duplicates: there are very few of them and keeping them would greatly hurt our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "4becd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('players.txt'):\n",
    "    non_unique_values = players_id_df.loc[players_id_df.duplicated('Final ID', keep=False), 'Final ID'].unique()\n",
    "    players_df = players_id_df[~players_id_df['Final ID'].isin(non_unique_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "6a93e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('players.txt'):\n",
    "    with pd.option_context('mode.chained_assignment', None):\n",
    "        players_df['Final ID'] = players_df['Final ID'].apply(remove_accents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03286cc",
   "metadata": {},
   "source": [
    "Removing the non-working ids from our selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "cc6bbde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('players.txt'):\n",
    "    ids = list(players_df['Final ID'].unique())\n",
    "\n",
    "    ids_to_remove = check_links(ids)\n",
    "    players_df = players_df[~players_df['Final ID'].isin(ids_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008102b8",
   "metadata": {},
   "source": [
    "Removing all the injured players that are not within the broader player set for some reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "260f43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('players.txt'):\n",
    "    intersection = set(injuries_df['Final ID']).intersection(set(players_df['Final ID']))\n",
    "    injuries_df = injuries_df[injuries_df['Final ID'].isin(intersection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca83fd",
   "metadata": {},
   "source": [
    "Showing that all injured players are inside the broader set of players with registered statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "38aaa790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ids are correct.\n"
     ]
    }
   ],
   "source": [
    "if len(set(injuries_df['Final ID']).intersection(set(players_df['Final ID']))) == len(injuries_df['Final ID'].unique()): \n",
    "    print(\"The ids are correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682dcc0",
   "metadata": {},
   "source": [
    "Saving the dataframe as txt to avoid having to reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "ee458a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('players.txt'):\n",
    "    players_df.to_csv('players.txt', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f1884",
   "metadata": {},
   "source": [
    "## Player game statistics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "id": "3d87b1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for douglto01\n",
      "Done for cunnija01\n",
      "Done for thybuma01\n",
      "Done for outlatr01\n",
      "Done for toddis01\n",
      "Done for mickejo01\n",
      "Done for howarjo01\n",
      "Done for sullija01\n",
      "Done for lowryky01\n",
      "Done for houstca01\n",
      "Done for connapa01\n",
      "Done for poirivi01\n",
      "Done for jonesje01\n",
      "Done for alkinra01\n",
      "Done for kuminjo01\n",
      "Done for gudurma01\n",
      "Done for greenaj01\n",
      "Done for careyve01\n",
      "Done for cacokde01\n",
      "Done for tayloty01\n",
      "Done for terryem01\n",
      "Done for mitchda01\n",
      "Done for obriejj01\n",
      "Done for grantdo01\n",
      "Done for johnsam01\n",
      "Done for mathega01\n",
      "Done for vucevni01\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('stats.txt'):\n",
    "    base_url = \"https://www.basketball-reference.com/players\"\n",
    "    stats = []\n",
    "\n",
    "    for player in list(players_df[\"Final ID\"].iloc[0:30]):\n",
    "        dfs = []\n",
    "        link = base_url + '/' + player[0] + '/' + player + '.html'\n",
    "        response = requests.get(link)\n",
    "        webpage = response.content\n",
    "\n",
    "        soup = BeautifulSoup(webpage, 'html.parser')\n",
    "        table = soup.find('table', {'id': 'per_game'})\n",
    "        if table == None: continue\n",
    "        avg_stats_df = pd.read_html(str(table))[0]\n",
    "\n",
    "        career_index = avg_stats_df[avg_stats_df[avg_stats_df.columns[0]] == 'Career'].index\n",
    "        if not career_index.empty: avg_stats_df = avg_stats_df.loc[:career_index[0] - 1]\n",
    "\n",
    "        shortened_seasons = [season[:2] + season[-2:] for season in list(avg_stats_df[\"Season\"].unique()) if 2012 <= int(season[:4]) < 2023]\n",
    "        if shortened_seasons == []: continue\n",
    "\n",
    "        for season in shortened_seasons:\n",
    "            link = base_url + '/' + player[0] + '/' + player + '/gamelog/' + season\n",
    "            response = requests.get(link)\n",
    "            time.sleep(3)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "            table = soup.find(\"table\", {\"id\": \"pgl_basic\"})\n",
    "            if table == None: continue\n",
    "            columns = [th.getText() for th in table.find(\"thead\").findAll(\"th\")][1:]\n",
    "            columns[4] = 'H/A'\n",
    "            columns[6] = 'W/L'\n",
    "\n",
    "            data_rows = table.find(\"tbody\").findAll(\"tr\")\n",
    "            data = [[td.getText() for td in data_rows[i].findAll(\"td\")] for i in range(len(data_rows))]\n",
    "\n",
    "            data = [row for row in data if row and row[0] != '']\n",
    "            df_season = pd.DataFrame(data, columns=columns)\n",
    "            df_season.insert(0, 'Season', season)\n",
    "            if len(df_season) == 0: continue\n",
    "                \n",
    "            df_season = df_season.drop(columns=['Tm', 'Opp', 'FG%', '3P%', 'FT%', 'W/L'])\n",
    "            df_season['H/A'] = df_season['H/A'].replace('@', '1').replace('', '0')\n",
    "            df_season[\"+/-\"] = df_season[\"+/-\"].str.replace('+', '')\n",
    "\n",
    "            df_season['Age'] = df_season['Age'].apply(lambda x: int(x.split('-')[0]) + int(x.split('-')[1])/365)\n",
    "            df_season['Age'] = df_season['Age'].round(1)\n",
    "            df_season['MP'] = df_season['MP'].apply(lambda x: int(x.split(':')[0]) + int(x.split(':')[1])/60)\n",
    "            df_season.replace('', 0, inplace=True)\n",
    "\n",
    "            average_series = df_season.drop(columns=['Season', 'G', 'Date', 'Age', 'H/A', 'GS', '+/-']).astype(float).mean()\n",
    "            average_df_season = pd.DataFrame(average_series).T\n",
    "\n",
    "            for column in average_df_season.columns:\n",
    "                if average_df_season[column][0] != 0:\n",
    "                    df_season[column] = (df_season[column].astype(float) / average_df_season[column][0]).round(2)\n",
    "                else:\n",
    "                    df_season[column] = 0\n",
    "\n",
    "            dfs.append(df_season)\n",
    "\n",
    "        if len(dfs) > 0:\n",
    "            final_df = pd.concat(dfs, ignore_index=True)\n",
    "            print(\"Done for \" + str(player))\n",
    "\n",
    "            final_df.insert(0, 'Player', player)\n",
    "            final_df.insert(1, 'Inj After', 0)\n",
    "\n",
    "            stats.append(final_df)\n",
    "\n",
    "    stats_df = pd.concat(stats, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9c7b8",
   "metadata": {},
   "source": [
    "Saving the dataframe as txt to avoid having to reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "id": "b30495b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('stats.txt'):\n",
    "    stats_df.to_csv('stats.txt', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06974811",
   "metadata": {},
   "source": [
    "## Statistics enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53f12b",
   "metadata": {},
   "source": [
    "We want to translate a current trend that a given player has followed in his past games. We will add stats for the previous game, as well as the past three and five games. Some injuries are developped through time and effort, and those variables will try and capture that. Beyond the usual efficiency statistics, there are also the *H/A* stat that is interesting, as an accumulation of away games can have an effect on fatigue, as much as the number of games started within *GS*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "id": "28408350",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_columns = list(stats_df.columns)[6:]\n",
    "\n",
    "trend_columns = []\n",
    "for column_name in modified_columns:\n",
    "    trend_columns.append(column_name + \"_Last1\")\n",
    "    trend_columns.append(column_name + \"_Last3\")\n",
    "    trend_columns.append(column_name + \"_Last5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a528242",
   "metadata": {},
   "source": [
    "For each player and for each season, we will compute those average trend statistics. We will therefore have to drop individual seasons with fewer than six games (current one + the five past games). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "id": "da19f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df_above = stats_df[stats_df['G'].astype(float) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "id": "0fbf7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_df = pd.DataFrame()\n",
    "\n",
    "for column_name in trend_columns: modified_df[column_name] = 0\n",
    "\n",
    "stats_df_above = pd.concat([stats_df_above, modified_df], axis=1)\n",
    "stats_df_above.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "id": "68b816de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, game in stats_df_above.iterrows():\n",
    "    static = idx\n",
    "    player = game[\"Player\"]\n",
    "    season = game[\"Season\"]\n",
    "    count = int(game[\"G\"])\n",
    "          \n",
    "    last1_row = stats_df[(stats_df['Player'] == player) &  (stats_df['Season'] == season) & (stats_df['G'].astype(int) == count - 1)]\n",
    "    last2_row = stats_df[(stats_df['Player'] == player) &  (stats_df['Season'] == season) & (stats_df['G'].astype(int) == count - 2)]\n",
    "    last3_row = stats_df[(stats_df['Player'] == player) &  (stats_df['Season'] == season) & (stats_df['G'].astype(int) == count - 3)]\n",
    "    last4_row = stats_df[(stats_df['Player'] == player) &  (stats_df['Season'] == season) & (stats_df['G'].astype(int) == count - 4)]\n",
    "    last5_row = stats_df[(stats_df['Player'] == player) &  (stats_df['Season'] == season) & (stats_df['G'].astype(int) == count - 5)]\n",
    "\n",
    "    last1_row = last1_row[list(stats_df.columns)[6:]].astype(float)\n",
    "    last2_row = last2_row[list(stats_df.columns)[6:]].astype(float)\n",
    "    last3_row = last3_row[list(stats_df.columns)[6:]].astype(float)\n",
    "    last4_row = last4_row[list(stats_df.columns)[6:]].astype(float)\n",
    "    last5_row = last5_row[list(stats_df.columns)[6:]].astype(float)\n",
    "\n",
    "    last3_avg = pd.DataFrame(last1_row.values + last2_row.values + last3_row.values) / 3\n",
    "    last5_avg = pd.DataFrame(last1_row.values + last2_row.values + last3_row.values + last4_row.values + last5_row.values) / 5\n",
    "    \n",
    "    last3_avg.columns = last1_row.columns + \"_Last3\"\n",
    "    last5_avg.columns = last1_row.columns + \"_Last5\"\n",
    "    last1_row.columns = last1_row.columns + \"_Last1\"\n",
    "    \n",
    "    last1_row.reset_index(drop=True, inplace=True)\n",
    "    last3_avg.reset_index(drop=True, inplace=True)\n",
    "    last5_avg.reset_index(drop=True, inplace=True)\n",
    "    result = pd.concat([last1_row, last3_avg, last5_avg], axis=1)\n",
    "    \n",
    "    stats_df_above.loc[static, result.columns] = result.iloc[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713db93f",
   "metadata": {},
   "source": [
    "## Linking the injury variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0aee42",
   "metadata": {},
   "source": [
    "Now that we have an entire dataset for all individual games played for the period, we must link the injury list to pinpoint what games led to player injuries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "id": "395a1562",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df_above['Date'] = pd.to_datetime(stats_df_above['Date'])\n",
    "injuries_df['Date'] = pd.to_datetime(injuries_df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df09a42f",
   "metadata": {},
   "source": [
    "Returns the set of exact dates before an injury was registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "id": "feaa08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gameBeforeInjuryFinder(injury_dates, all_dates):\n",
    "    most_recent_dates = []\n",
    "\n",
    "    for small_date in injury_dates:\n",
    "        before_dates = all_dates[all_dates < small_date]\n",
    "\n",
    "        if not before_dates.empty:\n",
    "            most_recent_date = before_dates.max()\n",
    "            most_recent_dates.append(most_recent_date)\n",
    "        else:\n",
    "            most_recent_dates.append(None)\n",
    "\n",
    "    return set(most_recent_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0368b80d",
   "metadata": {},
   "source": [
    "Looping through all players on the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "id": "1885f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in list(stats_df_above[\"Player\"].unique()):\n",
    "\n",
    "    injury_dates = list(injuries_df.loc[injuries_df['Final ID'] == player, 'Date'])\n",
    "    all_dates = stats_df_above.loc[stats_df_above['Player'] == player, 'Date']\n",
    "\n",
    "    most_recent_dates_set = gameBeforeInjuryFinder(injury_dates, all_dates)\n",
    "    stats_df_above = stats_df_above.copy()\n",
    "    stats_df_above['Inj After'] = stats_df_above.apply(lambda row: 1 if row['Date'] in most_recent_dates_set else row['Inj After'], axis=1)\n",
    "\n",
    "columns_to_select = modified_columns + trend_columns\n",
    "stats_df = stats_df_above.loc[:, columns_to_select].astype(float).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "id": "3ee91269",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('stats_full.txt'):\n",
    "    stats_df.to_csv('stats_full.txt', sep=' ', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
