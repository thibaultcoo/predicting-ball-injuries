{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f883a50",
   "metadata": {},
   "source": [
    "# Predicting basketball injuries using ML\n",
    "### Alternative finance project\n",
    "\n",
    "Supervised by Prof. Marcus Frunza - coded by **Soughati Kenza, Henry-Biabaud Briac, Collin Thibault**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9677e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffffcc; border: 1px solid #d0d0d0; padding: 10px;\">\n",
    "\n",
    "The aim of this project was to work around machine learning models to predict NBA basketball player injuries for the next game-ahead, using a collection of box score individual statistics from previous games.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81e1ad",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f0f0; border: 1px solid #d0d0d0; padding: 10px;\">\n",
    "Having already extracted all the data required, we now work on implementing machine learning techniques to analyze the sets and work on the prediction.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36231f18",
   "metadata": {},
   "source": [
    "# Loading general libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9cf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b074919",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74874149",
   "metadata": {},
   "source": [
    "Because our set are so imbalanced by nature (barely 5% of all individual games result in an injury) we have to rebalance conveniently our data. We perform *cluster-based resampling* to preserve patterns and only remove what can be considered as close duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "339d8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv('stats_full.txt', sep=' ')\n",
    "\n",
    "y_df = stats_df[['Inj After']]\n",
    "x_df = stats_df.drop(columns=['Inj After', 'Player', 'Date', 'Season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729fb76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "majority_class_indices = y_df[y_df['Inj After'] == 0].index\n",
    "minority_class_indices = y_df[y_df['Inj After'] == 1].index\n",
    "\n",
    "kmeans = KMeans(n_clusters=len(minority_class_indices), random_state=203)\n",
    "kmeans.fit(x_df.loc[majority_class_indices])\n",
    "\n",
    "x_df_majority_undersampled = pd.DataFrame(kmeans.cluster_centers_, columns=x_df.columns.tolist())\n",
    "x_df_minority = x_df.loc[minority_class_indices]\n",
    "\n",
    "x_df_balanced = pd.concat([x_df_majority_undersampled, x_df_minority], ignore_index=True)\n",
    "y_df_balanced = np.concatenate([np.zeros(len(x_df_majority_undersampled)), np.ones(len(minority_class_indices))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a1b7d",
   "metadata": {},
   "source": [
    "Splitting our set into training and set sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_df_balanced, y_df_balanced, test_size=0.2, random_state=203)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c603ca8",
   "metadata": {},
   "source": [
    "# Features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca8d91",
   "metadata": {},
   "source": [
    "Performing PCA to remove poor feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(x_df_balanced.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if pcaSelection:\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x_train[features])\n",
    "\n",
    "    pca = PCA(n_components=0.975)\n",
    "    x_pca = pca.fit_transform(x_scaled)\n",
    "    n_components_chosen = pca.n_components_\n",
    "\n",
    "    components_abs = np.abs(pca.components_)\n",
    "    important_feature_indices = np.argmax(components_abs, axis=1)\n",
    "    features = [features[i] for i in important_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19dc455",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb84471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(cleaned_df_train_team, df_scores, test_size=0.2, random_state=20)\n",
    "x_train = x_train[features]\n",
    "x_val = x_val[features]\n",
    "x_test = cleaned_df_test_team[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4bfab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "if xgBoost:\n",
    "    label_encoder = LabelEncoder()    \n",
    "    y_train_ready_encoded = label_encoder.fit_transform(y_train.apply(map_label, axis=1))\n",
    "    y_val_ready_encoded = label_encoder.transform(y_val.apply(map_label, axis=1))\n",
    "    \n",
    "    param_grid = {\n",
    "        'xgboost__n_estimators': [40],\n",
    "        'xgboost__max_depth': [5, 7],\n",
    "        'xgboost__learning_rate': [0.01, 0.15],\n",
    "        'xgboost__subsample': [0.6, 0.8],\n",
    "        'xgboost__colsample_bytree': [0.7, 1.0]\n",
    "    }\n",
    "\n",
    "    xgb_pipeline = Pipeline([('xgboost', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))])\n",
    "    grid_search = GridSearchCV(xgb_pipeline, param_grid, cv=10, n_jobs=-1, scoring='accuracy', verbose=True)\n",
    "    grid_search.fit(x_train, y_train_ready_encoded)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_model.fit(x_train, y_train_ready_encoded)\n",
    "    \n",
    "    print(\"Best parameters found: \", best_params)\n",
    "\n",
    "    pred_train = best_model.predict(x_train)\n",
    "    pred_train = pd.Series(pred_train, index=y_train.index)\n",
    "    pred_train = label_encoder.inverse_transform(pred_train)\n",
    "    \n",
    "    pred_val = best_model.predict(x_val)\n",
    "    pred_val = pd.Series(pred_val, index=y_val.index)\n",
    "    pred_val = label_encoder.inverse_transform(pred_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
